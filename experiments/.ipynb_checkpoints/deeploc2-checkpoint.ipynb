{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/TviNet/DeepLoc-2.0.git"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cloning into 'DeepLoc-2.0'...\nremote: Enumerating objects: 95, done.\u001B[K\nremote: Counting objects: 100% (95/95), done.\u001B[K\nremote: Compressing objects: 100% (60/60), done.\u001B[K\nremote: Total 95 (delta 37), reused 89 (delta 32), pack-reused 0\u001B[K\nReceiving objects: 100% (95/95), 17.96 MiB | 7.25 MiB/s, done.\nResolving deltas: 100% (37/37), done.\nUpdating files: 100% (31/31), done.\n"
    }
   ],
   "execution_count": 1,
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install Bio\n",
    "!pip install pickle5\n",
    "!pip install fair-esm"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting pytorch_lightning\n  Downloading pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\n\u001B[K     |████████████████████████████████| 801 kB 6.0 MB/s eta 0:00:01\n\u001B[?25hRequirement already satisfied: tqdm>=4.57.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pytorch_lightning) (4.65.0)\nCollecting torch>=1.13.0\n  Downloading torch-2.2.1-cp38-cp38-manylinux1_x86_64.whl (755.5 MB)\n\u001B[K     |████████████████████████████████| 755.5 MB 3.7 kB/s  eta 0:00:012\n\u001B[?25hRequirement already satisfied: PyYAML>=5.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pytorch_lightning) (6.0)\nRequirement already satisfied: numpy>=1.17.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pytorch_lightning) (1.21.6)\nRequirement already satisfied: fsspec[http]>=2022.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pytorch_lightning) (2023.5.0)\nRequirement already satisfied: typing-extensions>=4.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pytorch_lightning) (4.6.0)\nCollecting torchmetrics>=0.7.0\n  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n\u001B[K     |████████████████████████████████| 840 kB 78.0 MB/s eta 0:00:01\n\u001B[?25hCollecting lightning-utilities>=0.8.0\n  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pytorch_lightning) (23.0)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch>=1.13.0->pytorch_lightning) (2.11.2)\nCollecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001B[K     |████████████████████████████████| 121.6 MB 29 kB/s s eta 0:00:01\n\u001B[?25hCollecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001B[K     |████████████████████████████████| 56.5 MB 52 kB/s s eta 0:00:01\n\u001B[?25hCollecting sympy\n  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n\u001B[K     |████████████████████████████████| 5.7 MB 80.6 MB/s eta 0:00:01\n\u001B[?25hCollecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001B[K     |████████████████████████████████| 410.6 MB 2.4 kB/s s eta 0:00:01\n\u001B[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001B[K     |████████████████████████████████| 823 kB 76.9 MB/s eta 0:00:01\n\u001B[?25hCollecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001B[K     |████████████████████████████████| 124.2 MB 12 kB/s s eta 0:00:01\n\u001B[?25hCollecting nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001B[K     |████████████████████████████████| 166.0 MB 11 kB/s /s eta 0:00:01\n\u001B[?25hRequirement already satisfied: networkx in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch>=1.13.0->pytorch_lightning) (2.5)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001B[K     |████████████████████████████████| 23.7 MB 50.9 MB/s eta 0:00:01\n\u001B[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001B[K     |████████████████████████████████| 14.1 MB 47.0 MB/s eta 0:00:01\n\u001B[?25hCollecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001B[K     |████████████████████████████████| 99 kB 3.8 MB/s  eta 0:00:01\n\u001B[?25hCollecting triton==2.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.12\"\n  Downloading triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001B[K     |████████████████████████████████| 167.9 MB 7.2 kB/s  eta 0:00:01\n\u001B[?25hCollecting nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001B[K     |████████████████████████████████| 731.7 MB 4.1 kB/s  eta 0:00:011\n\u001B[?25hCollecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001B[K     |████████████████████████████████| 196.0 MB 22 kB/s s eta 0:00:011\n\u001B[?25hRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch>=1.13.0->pytorch_lightning) (3.12.0)\nRequirement already satisfied: requests; extra == \"http\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.8.4)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (65.6.3)\nRequirement already satisfied: MarkupSafe>=0.23 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.0.1)\nCollecting mpmath>=0.19\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001B[K     |████████████████████████████████| 536 kB 80.2 MB/s eta 0:00:01\n\u001B[?25hCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001B[K     |████████████████████████████████| 21.1 MB 42.0 MB/s eta 0:00:01\n\u001B[?25hRequirement already satisfied: decorator>=4.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from networkx->torch>=1.13.0->pytorch_lightning) (5.1.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (1.26.16)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (2022.9.24)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.3)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (23.1.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.4)\n\u001B[31mERROR: torch 2.2.1 has requirement typing-extensions>=4.8.0, but you'll have typing-extensions 4.6.0 which is incompatible.\u001B[0m\n\u001B[31mERROR: azureml-automl-dnn-nlp 1.51.0 has requirement torch<=1.12.0,>=1.5.0, but you'll have torch 2.2.1 which is incompatible.\u001B[0m\nInstalling collected packages: nvidia-cufft-cu12, nvidia-curand-cu12, mpmath, sympy, nvidia-cublas-cu12, nvidia-cuda-runtime-cu12, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, nvidia-nccl-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-nvtx-cu12, triton, nvidia-cudnn-cu12, torch, lightning-utilities, torchmetrics, pytorch-lightning\n  Attempting uninstall: torch\n    Found existing installation: torch 1.12.0\n    Uninstalling torch-1.12.0:\n      Successfully uninstalled torch-1.12.0\nSuccessfully installed lightning-utilities-0.10.1 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.2.1 sympy-1.12 torch-2.2.1 torchmetrics-1.3.1 triton-2.2.0\nCollecting Bio\n  Downloading bio-1.6.2-py3-none-any.whl (278 kB)\n\u001B[K     |████████████████████████████████| 278 kB 5.0 MB/s eta 0:00:01\n\u001B[?25hCollecting mygene\n  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\nCollecting biopython>=1.80\n  Downloading biopython-1.83-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001B[K     |████████████████████████████████| 3.1 MB 78.0 MB/s eta 0:00:01\n\u001B[?25hRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Bio) (2.31.0)\nCollecting pooch\n  Downloading pooch-1.8.1-py3-none-any.whl (62 kB)\n\u001B[K     |████████████████████████████████| 62 kB 602 kB/s  eta 0:00:01\n\u001B[?25hRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Bio) (4.65.0)\nCollecting gprofiler-official\n  Downloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Bio) (1.1.5)\nCollecting biothings-client>=0.2.6\n  Downloading biothings_client-0.3.1-py2.py3-none-any.whl (29 kB)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from biopython>=1.80->Bio) (1.21.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->Bio) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->Bio) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->Bio) (2022.9.24)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->Bio) (3.1.0)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pooch->Bio) (23.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pooch->Bio) (3.5.1)\nRequirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->Bio) (2022.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas->Bio) (2.8.2)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->Bio) (1.16.0)\nInstalling collected packages: biothings-client, mygene, biopython, pooch, gprofiler-official, Bio\nSuccessfully installed Bio-1.6.2 biopython-1.83 biothings-client-0.3.1 gprofiler-official-1.0.0 mygene-3.2.2 pooch-1.8.1\nCollecting pickle5\n  Downloading pickle5-0.0.11.tar.gz (132 kB)\n\u001B[K     |████████████████████████████████| 132 kB 4.6 MB/s eta 0:00:01\n\u001B[?25hBuilding wheels for collected packages: pickle5\n  Building wheel for pickle5 (setup.py) ... \u001B[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n\u001B[?25h  Created wheel for pickle5: filename=pickle5-0.0.11-cp38-cp38-linux_x86_64.whl size=290280 sha256=5a73d0f450c497d83f48f8e8f20d25592032a5efc29548fe0f7b677331d26d54\n  Stored in directory: /home/azureuser/.cache/pip/wheels/25/d4/61/dbd8edd1a0d656be7b4267c85db3b61951eb60016a0154a122\nSuccessfully built pickle5\nInstalling collected packages: pickle5\nSuccessfully installed pickle5-0.0.11\nCollecting fair-esm\n  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n\u001B[K     |████████████████████████████████| 93 kB 467 kB/s eta 0:00:011\n\u001B[?25hInstalling collected packages: fair-esm\nSuccessfully installed fair-esm-2.0.0\n"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "IOPub data rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_data_rate_limit`.\n\nCurrent values:\nServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\nIOPub data rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_data_rate_limit`.\n\nCurrent values:\nServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\nIOPub data rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_data_rate_limit`.\n\nCurrent values:\nServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\nIOPub data rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_data_rate_limit`.\n\nCurrent values:\nServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\nIOPub data rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_data_rate_limit`.\n\nCurrent values:\nServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\n"
    }
   ],
   "execution_count": 9,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !cd ./DeepLoc-2.0/\n",
    "!pwd"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 3,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-03-20T17:02:39.874868Z",
     "start_time": "2024-03-20T17:02:39.830670Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python train_sl.py --model Accurate"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n  warnings.warn(\"Can't initialize NVML\")\nEmbeddings not found, generating......\nDownloading: 100%|█████████████████████████| 10.5G/10.5G [02:54<00:00, 64.8MB/s]\nSome weights of the model checkpoint at Rostlab/prot_t5_xl_uniref50 were not used when initializing T5EncoderModel: ['decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.embed_tokens.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'lm_head.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight']\n- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n13it [1:40:13, 459.34s/it]^C\n"
    }
   ],
   "execution_count": 1,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
